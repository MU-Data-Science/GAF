{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SRR794398', 'ERR020241', 'ERR022393', 'ERR062924', 'ERR018442',\n",
       "       'ERR018550', 'ERR018454', 'ERR018448', 'ERR018463', 'ERR018436',\n",
       "       'ERR023204', 'ERR022463', 'ERR016316', 'ERR018197', 'ERR018423',\n",
       "       'ERR018491', 'ERR062953', 'ERR062973'],\n",
       "      dtype='object', name='Run')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Importing data\n",
    "metadata = pd.read_csv('metadata_labeled.csv')\n",
    "metadata = metadata.drop_duplicates(subset='Run', keep='first')\n",
    "metadata = metadata.drop('Label',axis=1)\n",
    "multiqc = pd.read_csv('multiqc_data.csv')\n",
    "label= pd.read_csv('labels.csv',sep='\\t')\n",
    "#Merge metadata and execution dataframe on Run\n",
    "df = pd.merge(metadata, multiqc, on='Run', how='inner')\n",
    "df = pd.merge(df, label, on='Run', how='inner')\n",
    "df.index = df['Run']\n",
    "#Removing columns with no data\n",
    "df = df.dropna(axis=1, how='all')\n",
    "#Removing columns with only one unique value\n",
    "df = df.loc[:,df.apply(pd.Series.nunique) != 1]\n",
    "#Removing columns with more than 40% missing values\n",
    "df = df.loc[:, df.isnull().mean() < .4]\n",
    "#Removing columns with more than 40% zeros\n",
    "df = df.loc[:, (df == 0).mean() < .4]\n",
    "#Remove non-numeric columns\n",
    "df = df.select_dtypes(include=[np.number])\n",
    "df = df.loc[:,~df.columns.duplicated()]\n",
    "#shuffle df\n",
    "df = df.sample(frac=1)\n",
    "# remove 'None_mqc-generalstats-fastqc-percent_duplicates', 'None_mqc-generalstats-fastqc-percent_gc', 'None_mqc-generalstats-fastqc-avg_sequence_length', 'None_mqc-generalstats-fastqc-median_sequence_length', 'None_mqc-generalstats-fastqc-percent_fails', 'None_mqc-generalstats-fastqc-total_sequences coluumns from df\n",
    "df = df.drop(['None_mqc-generalstats-fastqc-percent_duplicates', 'None_mqc-generalstats-fastqc-percent_gc', 'None_mqc-generalstats-fastqc-avg_sequence_length', 'None_mqc-generalstats-fastqc-median_sequence_length', 'None_mqc-generalstats-fastqc-percent_fails', 'None_mqc-generalstats-fastqc-total_sequences'], axis=1)\n",
    "X = df.iloc[:,0:-5] #features\n",
    "y = df.iloc[:,-5:] #labels\n",
    "sc=StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "X_train = X[0:80]; X_test = X[80:]\n",
    "y_train = y[0:80]; y_test = y[80:]\n",
    "del label, metadata, multiqc, sc\n",
    "y_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test for other samples here\n",
    "# metadata_test = pd.read_csv('metadata_test.csv'); multiqc_test = pd.read_csv('multiqc_testdata.csv')\n",
    "# # metadata_test = metadata_test.drop_duplicates(subset='Run', keep='first')\n",
    "# df_test = pd.merge(metadata_test, multiqc_test, on='Run', how='inner'); df_test.index = df_test['Run']\n",
    "# df = df.drop(['M1', 'M2', 'M3', 'M4', 'M5'], axis=1)\n",
    "# features = df.columns; \n",
    "# df_test = df_test[features]\n",
    "# sc=StandardScaler()\n",
    "# X_test2 = sc.fit_transform(df_test); del df_test, metadata_test, multiqc_test, sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 86.83555555555557\n",
      "Mean Squared Error: 17615.029533333334\n",
      "R2 Score: 0.9377097162915822\n",
      "Correlation: 0.9711747166935497\n",
      "actual_vs_predicted.csv file is created in the current working directory\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SRR794398</th>\n",
       "      <td>1118</td>\n",
       "      <td>1112.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR020241</th>\n",
       "      <td>2152</td>\n",
       "      <td>2170.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR022393</th>\n",
       "      <td>714</td>\n",
       "      <td>765.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR062924</th>\n",
       "      <td>448</td>\n",
       "      <td>488.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR018442</th>\n",
       "      <td>1250</td>\n",
       "      <td>1276.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR018550</th>\n",
       "      <td>649</td>\n",
       "      <td>646.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR018454</th>\n",
       "      <td>1405</td>\n",
       "      <td>1225.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR018448</th>\n",
       "      <td>659</td>\n",
       "      <td>736.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR018463</th>\n",
       "      <td>728</td>\n",
       "      <td>836.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR018436</th>\n",
       "      <td>631</td>\n",
       "      <td>735.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR023204</th>\n",
       "      <td>904</td>\n",
       "      <td>943.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR022463</th>\n",
       "      <td>1651</td>\n",
       "      <td>1294.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR016316</th>\n",
       "      <td>379</td>\n",
       "      <td>429.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR018197</th>\n",
       "      <td>929</td>\n",
       "      <td>906.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR018423</th>\n",
       "      <td>645</td>\n",
       "      <td>974.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR018491</th>\n",
       "      <td>2237</td>\n",
       "      <td>2150.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR062953</th>\n",
       "      <td>758</td>\n",
       "      <td>707.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERR062973</th>\n",
       "      <td>614</td>\n",
       "      <td>601.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Actual  Predicted\n",
       "Run                         \n",
       "SRR794398    1118    1112.59\n",
       "ERR020241    2152    2170.04\n",
       "ERR022393     714     765.32\n",
       "ERR062924     448     488.55\n",
       "ERR018442    1250    1276.42\n",
       "ERR018550     649     646.16\n",
       "ERR018454    1405    1225.05\n",
       "ERR018448     659     736.24\n",
       "ERR018463     728     836.00\n",
       "ERR018436     631     735.56\n",
       "ERR023204     904     943.56\n",
       "ERR022463    1651    1294.53\n",
       "ERR016316     379     429.97\n",
       "ERR018197     929     906.63\n",
       "ERR018423     645     974.99\n",
       "ERR018491    2237    2150.48\n",
       "ERR062953     758     707.88\n",
       "ERR062973     614     601.29"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with M1 machine\n",
    "machine_name = 'M5'   # Enter your machine name here\n",
    "y_train_machine = y_train[machine_name]\n",
    "y_test_machine = y_test[machine_name]\n",
    "\n",
    "# Initialize and train the model\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train_machine)\n",
    "\n",
    "# Predict the values\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Create a DataFrame for the actual and predicted values\n",
    "df_res = pd.DataFrame({'Actual': y_test_machine, 'Predicted': y_pred})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_res.to_csv('actual_vs_predicted.csv', index=True)\n",
    "\n",
    "# Calculate and print evaluation metrics\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_machine, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test_machine, y_pred))\n",
    "print('R2 Score:', metrics.r2_score(y_test_machine, y_pred))\n",
    "print('Correlation:', df_res['Actual'].corr(df_res['Predicted']))\n",
    "print(\"actual_vs_predicted.csv file is created in the current working directory\")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict for new test data\n",
    "# y_pred2 = model.predict(X_test2)\n",
    "# pd.DataFrame(y_pred2).to_csv('predicted_testdata.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
