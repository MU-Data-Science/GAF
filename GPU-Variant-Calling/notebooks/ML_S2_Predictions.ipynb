{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Machine you are using, like M1 as 1, M2 as 2, M3 as 3...so on\n",
      "You have selected Machine 5\n"
     ]
    }
   ],
   "source": [
    "#Importing data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Define the models\n",
    "\n",
    "models = [\n",
    "    ('Lasso Regression', Lasso()),\n",
    "    ('Random Forest', RandomForestRegressor()),\n",
    "    ('XGBoost', XGBRegressor())\n",
    "]\n",
    "\n",
    "# models = [\n",
    "#     ('Linear Regression', LinearRegression()),\n",
    "#     ('Lasso Regression', Lasso()),\n",
    "#     ('Ridge Regression', Ridge()),\n",
    "#     ('SVM', SVR()),\n",
    "#     ('Random Forest', RandomForestRegressor()),\n",
    "#     ('Decision Tree', DecisionTreeRegressor()),\n",
    "#     ('Neural Network', MLPRegressor(max_iter=50000)),\n",
    "#     ('XGBoost', XGBRegressor())\n",
    "# ]\n",
    "#Importing data\n",
    "#for 99 samples we are providing the metadata file here\n",
    "metadata = pd.read_csv('metadata_labeled.csv')\n",
    "metadata = metadata.drop_duplicates(subset='Run', keep='first')\n",
    "metadata = metadata.drop('Label',axis=1)\n",
    "#This is multiqc quality data file\n",
    "multiqc = pd.read_csv('multiqc_data.csv')\n",
    "#we are passing the labels file here\n",
    "labels= pd.read_csv('labels_splitted.csv',sep='\\t')\n",
    "#Merging the metadata and multiqc data\n",
    "all_features = pd.merge(metadata, multiqc, on='Run', how='inner')\n",
    "print(\"Enter the Machine you are using, like M1 as 1, M2 as 2, M3 as 3...so on\")\n",
    "input_machine = input()\n",
    "#extract for M0 from label dataframe along with Run column\n",
    "label_1= labels.iloc[:,[0,(int(input_machine)*2)-1]]\n",
    "label_2= labels.iloc[:,[0,int(input_machine)*2]]\n",
    "print(\"You have selected Machine\", input_machine)\n",
    "#rename the last column as label\n",
    "label_1.columns = ['Run','Label']\n",
    "label_2.columns = ['Run','Label']\n",
    "#conver the label column as integer\n",
    "# label_1['Label'] = label_1['Label'].astype(int)\n",
    "# label_2['Label'] = label_2['Label'].astype(int)\n",
    "#merging fq2bam labels with all_features\n",
    "all_features_df1 = pd.merge(all_features, label_1, on='Run', how='inner')\n",
    "#merging haplotype labels with all_features\n",
    "all_features_df2 = pd.merge(all_features, label_2, on='Run', how='inner')\n",
    "# remove columns with no data\n",
    "all_features_df1 = all_features_df1.dropna(axis=1, how='all')\n",
    "all_features_df2 = all_features_df2.dropna(axis=1, how='all')\n",
    "# remove columns wiht only one unique value\n",
    "all_features_df1 = all_features_df1.loc[:,all_features_df1.apply(pd.Series.nunique) != 1]\n",
    "all_features_df2 = all_features_df2.loc[:,all_features_df2.apply(pd.Series.nunique) != 1]\n",
    "# remove columns with more than 40% missing values\n",
    "all_features_df1 = all_features_df1.loc[:,all_features_df1.isnull().mean() < 0.4]\n",
    "all_features_df2 = all_features_df2.loc[:,all_features_df2.isnull().mean() < 0.4]\n",
    "# remove columns with more than 40% zeros\n",
    "all_features_df1 = all_features_df1.loc[:,(all_features_df1 == 0).mean() < 0.4]\n",
    "all_features_df2 = all_features_df2.loc[:,(all_features_df2 == 0).mean() < 0.4]\n",
    "# remove non-numeric columns\n",
    "all_features_df1 = all_features_df1.select_dtypes(include=[np.number])\n",
    "all_features_df2 = all_features_df2.select_dtypes(include=[np.number])\n",
    "#remove all NaN values\n",
    "#Replace nan with mean of that column\n",
    "all_features_df1 = all_features_df1.fillna(all_features_df1.mean())\n",
    "all_features_df2 = all_features_df2.fillna(all_features_df2.mean())\n",
    "del metadata, multiqc, labels, label_1, label_2, input_machine, all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "def train(X, y):\n",
    "    # Scale the data\n",
    "    sc = StandardScaler()\n",
    "    X = sc.fit_transform(X)\n",
    "\n",
    "    # Define a function to train a model and calculate metrics using cross-validation\n",
    "    def train_and_evaluate(model, X, y):\n",
    "        kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "        mae_scores = cross_val_score(model, X, y, cv=kf, scoring='neg_mean_absolute_error')\n",
    "        mse_scores = cross_val_score(model, X, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "        r2_scores = cross_val_score(model, X, y, cv=kf, scoring='r2')\n",
    "\n",
    "        mae = -mae_scores.mean()\n",
    "        mse = -mse_scores.mean()\n",
    "        r2 = r2_scores.mean()\n",
    "\n",
    "        try:\n",
    "            model.fit(X, y)\n",
    "            feature_importance = model.feature_importances_\n",
    "        except AttributeError:\n",
    "            feature_importance = None\n",
    "\n",
    "        return mae, mse, r2, feature_importance\n",
    "\n",
    "    # Define a function to display the metrics in a table\n",
    "    def display_results(results):\n",
    "        print(f\"{'Model':<20}{'MAE':<10}{'MSE':<10}{'R2':<10}\")\n",
    "        for name, metrics in results.items():\n",
    "            mae, mse, r2, feature_importance = metrics\n",
    "            if feature_importance is not None:\n",
    "                feature_importance = [f\"{value:.2f}\" for value in feature_importance]\n",
    "                feature_importance = ' '.join(feature_importance)\n",
    "            else:\n",
    "                feature_importance = ''\n",
    "            print(f\"{name:<20}{mae:<10.2f}{mse:<10.2f}{r2:<10.2f}\")\n",
    "\n",
    "    # Train each model, calculate the metrics, and add the results to the table\n",
    "    results = {}\n",
    "    for name, model in models:\n",
    "        results[name] = train_and_evaluate(model, X, y)\n",
    "\n",
    "    # Sort the results based on R2 value\n",
    "    results_sorted = dict(sorted(results.items(), key=lambda item: item[1][2], reverse=True))\n",
    "    display_results(results_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1155\n",
       "1     1149\n",
       "2     1071\n",
       "3     1092\n",
       "4      412\n",
       "      ... \n",
       "93     352\n",
       "94     263\n",
       "95     342\n",
       "96    1224\n",
       "97     247\n",
       "Name: Label, Length: 98, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the models for stage-I fq2bam\n",
    "df_all_features = all_features_df1\n",
    "df_all_features[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CASE 1 WITH 386 FEATURES\n",
    "# df = df_all_features\n",
    "# X = df_all_features\n",
    "# X = X.loc[:,~X.columns.duplicated()]\n",
    "# labelencoder = LabelEncoder()\n",
    "# X['Label'] = labelencoder.fit_transform(X['Label'])\n",
    "# y = X['Label']\n",
    "# X=X.drop('Label', axis=1)\n",
    "# # print(\"CASE 1 WITH 386 FEATURES\")\n",
    "# # train(X,y)\n",
    "# # print(\"Change the model here\")\n",
    "# model = RandomForestRegressor()\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# model.fit(X_train, y_train)\n",
    "# feature_importance = model.feature_importances_\n",
    "# features = X.columns\n",
    "# features_importance = dict(zip(features, feature_importance))\n",
    "# features_importance = dict(sorted(features_importance.items(), key=lambda item: item[1], reverse=True))\n",
    "# features_importance = dict(list(features_importance.items())[:10])\n",
    "# features_importance\n",
    "# # CASE 2 WITH TOP-10 FEATURES\n",
    "# # keep the features only in top_features from features_importance\n",
    "# features_importance = list(features_importance.keys())\n",
    "# top_features = X[features_importance]\n",
    "# top_features['Label'] = y\n",
    "# X = top_features\n",
    "# labelencoder = LabelEncoder()\n",
    "# X['Label'] = labelencoder.fit_transform(X['Label'])\n",
    "# y = X['Label']\n",
    "# X=X.drop('Label', axis=1)\n",
    "# # print(\"CASE 2 WITH TOP-10 FEATURES\")\n",
    "# # train(X,y)\n",
    "# # CASE 3 WITH SIZE_ONLY FEATURE\n",
    "# df_size_only = df.loc[:,['size_MB','Label']] #size_only feature\n",
    "# X = df_size_only\n",
    "# labelencoder = LabelEncoder()\n",
    "# X['Label'] = labelencoder.fit_transform(X['Label'])\n",
    "# y = X['Label']\n",
    "# X=X.drop('Label', axis=1)\n",
    "# print(X.shape)\n",
    "# print(\"CASE 3 WITH SIZE_ONLY FEATURE\")\n",
    "# train(X,y)\n",
    "# # CASE 4 SELECTED FEATURES ONLY\n",
    "# selected_features = ['size_MB', 'bases', 'InsertSize', 'None_mqc-generalstats-fastqc-total_sequences', 'spots','spots_with_mates','Unique Reads','Duplicate Reads']\n",
    "# selected_features_df = df[selected_features]\n",
    "# selected_features_df['Label'] = y\n",
    "# X = selected_features_df\n",
    "# labelencoder = LabelEncoder()\n",
    "# X['Label'] = labelencoder.fit_transform(X['Label'])\n",
    "# y = X['Label']\n",
    "# X=X.drop('Label', axis=1)\n",
    "# # print(\"CASE 4 SELECTED FEATURES ONLY\")\n",
    "# # train(X,y)\n",
    "# # Case 5 with combined features\n",
    "# #create a column that contains sum of pbsq of all columns prefix with pbsq and then remove all pbsq columns except the sum column\n",
    "# pbsq_columns = [col for col in df.columns if 'pbsq' in col]\n",
    "# pbnc_columns = [col for col in df.columns if 'pbnc' in col]\n",
    "# psgc_columns = [col for col in df.columns if 'psgc' in col]\n",
    "# psgcp_columns = [col for col in df.columns if 'psgcp' in col]\n",
    "# pss_columns = [col for col in df.columns if 'pss' in col]\n",
    "# sdl_columns = [col for col in df.columns if 'sdl' in col]\n",
    "# df['sum_pbnc'] = df[pbnc_columns].sum(axis=1)\n",
    "# df['sum_pbsq'] = df[pbsq_columns].sum(axis=1)\n",
    "# df['sum_psgc'] = df[psgc_columns].sum(axis=1)\n",
    "# df['sum_psgcp'] = df[psgcp_columns].sum(axis=1)\n",
    "# df['sum_pss'] = df[pss_columns].sum(axis=1)\n",
    "# df['sdl'] = df[sdl_columns].sum(axis=1)\n",
    "# #remove all columns from df where prefix is pbsq\n",
    "# df = df.loc[:,~df.columns.str.startswith('pbsq')]\n",
    "# df = df.loc[:,~df.columns.str.startswith('pbnc')]\n",
    "# df=df.loc[:,~df.columns.str.startswith('psgc')]\n",
    "# df=df.loc[:,~df.columns.str.startswith('psgcp')]\n",
    "# df=df.loc[:,~df.columns.str.startswith('pss')]\n",
    "# df=df.loc[:,~df.columns.str.startswith('sdl')]  \n",
    "# #add sum_pbsq column to df\n",
    "# df['Label'] = y\n",
    "# X = df\n",
    "# labelencoder = LabelEncoder()\n",
    "# X['Label'] = labelencoder.fit_transform(X['Label'])\n",
    "# y = X['Label']\n",
    "# X=X.drop('Label', axis=1)\n",
    "# print(\"CASE 5 WITH COMBINED FEATURES\")\n",
    "# print(X.shape)\n",
    "# train(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For fq2bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98, 1)\n",
      "CASE 1 WITH SIZE_ONLY FEATURE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model               MAE       MSE       R2        \n",
      "Random Forest       9.70      196.50    0.70      \n",
      "XGBoost             10.77     242.30    0.63      \n",
      "Lasso Regression    11.52     237.05    0.60      \n"
     ]
    }
   ],
   "source": [
    "# CASE 3 WITH SIZE_ONLY FEATURE\n",
    "df = df_all_features\n",
    "X = df_all_features\n",
    "X = X.loc[:,~X.columns.duplicated()]\n",
    "labelencoder = LabelEncoder()\n",
    "X['Label'] = labelencoder.fit_transform(X['Label'])\n",
    "y = X['Label']\n",
    "X=X.drop('Label', axis=1)\n",
    "df_size_only = df.loc[:,['size_MB','Label']] #size_only feature\n",
    "X = df_size_only\n",
    "labelencoder = LabelEncoder()\n",
    "X['Label'] = labelencoder.fit_transform(X['Label'])\n",
    "y = X['Label']\n",
    "X=X.drop('Label', axis=1)\n",
    "print(X.shape)\n",
    "print(\"CASE 1 WITH SIZE_ONLY FEATURE\")\n",
    "train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 2 SELECTED FEATURES ONLY\n",
      "Model               MAE       MSE       R2        \n",
      "Random Forest       8.52      139.76    0.76      \n",
      "XGBoost             9.28      167.45    0.70      \n",
      "Lasso Regression    11.21     215.48    0.63      \n"
     ]
    }
   ],
   "source": [
    "# Case 6 SELECTED FEATURES ONLY - selected xx features\n",
    "# # With features mentioned in the draft paper\n",
    "df=df_all_features\n",
    "pbsq_columns = [col for col in df.columns if 'pbsq' in col]\n",
    "pbnc_columns = [col for col in df.columns if 'pbnc' in col]\n",
    "psgc_columns = [col for col in df.columns if 'psgc' in col]\n",
    "psgcp_columns = [col for col in df.columns if 'psgcp' in col]\n",
    "pss_columns = [col for col in df.columns if 'pss' in col]\n",
    "sdl_columns = [col for col in df.columns if 'sdl' in col]\n",
    "df['sum_pbnc'] = df[pbnc_columns].sum(axis=1)\n",
    "df['sum_pbsq'] = df[pbsq_columns].sum(axis=1)\n",
    "df['sum_psgc'] = df[psgc_columns].sum(axis=1)\n",
    "df['sum_psgcp'] = df[psgcp_columns].sum(axis=1)\n",
    "df['sum_pss'] = df[pss_columns].sum(axis=1)\n",
    "df['sdl'] = df[sdl_columns].sum(axis=1)\n",
    "#remove all columns from df where prefix is pbsq\n",
    "df = df.loc[:,~df.columns.str.startswith('pbsq')]\n",
    "df = df.loc[:,~df.columns.str.startswith('pbnc')]\n",
    "df=df.loc[:,~df.columns.str.startswith('psgc')]\n",
    "df=df.loc[:,~df.columns.str.startswith('psgcp')]\n",
    "df=df.loc[:,~df.columns.str.startswith('pss')]\n",
    "df=df.loc[:,~df.columns.str.startswith('sdl')]\n",
    "df.columns\n",
    "df_2 = df.loc[:,['spots','bases','avgLength','size_MB','InsertSize','None_mqc-generalstats-fastqc-percent_duplicates',\n",
    "                 'None_mqc-generalstats-fastqc-percent_gc','None_mqc-generalstats-fastqc-avg_sequence_length',\n",
    "                 'None_mqc-generalstats-fastqc-total_sequences','Unique Reads','fsch_Per Tile Sequence Quality',\n",
    "                 'fsch_Per Sequence Quality Scores','fsch_Per Base Sequence Content','fsch_Per Sequence GC Content',\n",
    "                 'fsch_Per Base N Content', 'fsch_Overrepresented Sequences','fsch_Per Base Sequence Quality',\n",
    "                 'sum_pbnc','sum_pbsq','sum_pss','sum_psgc'\n",
    "                 ]]\n",
    "df_2['Label'] = y\n",
    "X = df_2\n",
    "labelencoder = LabelEncoder()\n",
    "X['Label'] = labelencoder.fit_transform(X['Label'])\n",
    "y = X['Label']\n",
    "X=X.drop('Label', axis=1)\n",
    "print(\"Case 2 SELECTED FEATURES ONLY\")\n",
    "train(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For HTVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the models for stage-I htvc\n",
    "df_all_features = all_features_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98, 1)\n",
      "CASE 1 WITH SIZE_ONLY FEATURE\n",
      "Model               MAE       MSE       R2        \n",
      "Random Forest       9.62      204.97    0.67      \n",
      "XGBoost             9.22      207.55    0.65      \n",
      "Lasso Regression    10.59     215.20    0.61      \n"
     ]
    }
   ],
   "source": [
    "# CASE 3 WITH SIZE_ONLY FEATURE\n",
    "df = df_all_features\n",
    "X = df_all_features\n",
    "X = X.loc[:,~X.columns.duplicated()]\n",
    "labelencoder = LabelEncoder()\n",
    "X['Label'] = labelencoder.fit_transform(X['Label'])\n",
    "y = X['Label']\n",
    "X=X.drop('Label', axis=1)\n",
    "df_size_only = df.loc[:,['size_MB','Label']] #size_only feature\n",
    "X = df_size_only\n",
    "labelencoder = LabelEncoder()\n",
    "X['Label'] = labelencoder.fit_transform(X['Label'])\n",
    "y = X['Label']\n",
    "X=X.drop('Label', axis=1)\n",
    "print(X.shape)\n",
    "print(\"CASE 1 WITH SIZE_ONLY FEATURE\")\n",
    "train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 6 SELECTED FEATURES ONLY\n",
      "Model               MAE       MSE       R2        \n",
      "Random Forest       7.83      153.65    0.71      \n",
      "XGBoost             8.02      177.96    0.68      \n",
      "Lasso Regression    9.31      191.58    0.65      \n"
     ]
    }
   ],
   "source": [
    "# Case 6 SELECTED FEATURES ONLY - selected xx features\n",
    "# # With features mentioned in the draft paper\n",
    "df=df_all_features\n",
    "pbsq_columns = [col for col in df.columns if 'pbsq' in col]\n",
    "pbnc_columns = [col for col in df.columns if 'pbnc' in col]\n",
    "psgc_columns = [col for col in df.columns if 'psgc' in col]\n",
    "psgcp_columns = [col for col in df.columns if 'psgcp' in col]\n",
    "pss_columns = [col for col in df.columns if 'pss' in col]\n",
    "sdl_columns = [col for col in df.columns if 'sdl' in col]\n",
    "df['sum_pbnc'] = df[pbnc_columns].sum(axis=1)\n",
    "df['sum_pbsq'] = df[pbsq_columns].sum(axis=1)\n",
    "df['sum_psgc'] = df[psgc_columns].sum(axis=1)\n",
    "df['sum_psgcp'] = df[psgcp_columns].sum(axis=1)\n",
    "df['sum_pss'] = df[pss_columns].sum(axis=1)\n",
    "df['sdl'] = df[sdl_columns].sum(axis=1)\n",
    "#remove all columns from df where prefix is pbsq\n",
    "df = df.loc[:,~df.columns.str.startswith('pbsq')]\n",
    "df = df.loc[:,~df.columns.str.startswith('pbnc')]\n",
    "df=df.loc[:,~df.columns.str.startswith('psgc')]\n",
    "df=df.loc[:,~df.columns.str.startswith('psgcp')]\n",
    "df=df.loc[:,~df.columns.str.startswith('pss')]\n",
    "df=df.loc[:,~df.columns.str.startswith('sdl')]\n",
    "df.columns\n",
    "df_2 = df.loc[:,['spots','bases','avgLength','size_MB','InsertSize','None_mqc-generalstats-fastqc-percent_duplicates',\n",
    "                 'None_mqc-generalstats-fastqc-percent_gc','None_mqc-generalstats-fastqc-avg_sequence_length',\n",
    "                 'None_mqc-generalstats-fastqc-total_sequences','Unique Reads','fsch_Per Tile Sequence Quality',\n",
    "                 'fsch_Per Sequence Quality Scores','fsch_Per Base Sequence Content','fsch_Per Sequence GC Content',\n",
    "                 'fsch_Per Base N Content', 'fsch_Overrepresented Sequences','fsch_Per Base Sequence Quality',\n",
    "                 'sum_pbnc','sum_pbsq','sum_pss','sum_psgc'\n",
    "                 ]]\n",
    "df_2['Label'] = y\n",
    "X = df_2\n",
    "labelencoder = LabelEncoder()\n",
    "X['Label'] = labelencoder.fit_transform(X['Label'])\n",
    "y = X['Label']\n",
    "X=X.drop('Label', axis=1)\n",
    "print(\"Case 6 SELECTED FEATURES ONLY\")\n",
    "train(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
